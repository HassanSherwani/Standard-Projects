{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Regression\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
    "\n",
    "# Classification if needed\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Model helper\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)- Loading data-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('testset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>m10</th>\n",
       "      <th>...</th>\n",
       "      <th>m16</th>\n",
       "      <th>m17</th>\n",
       "      <th>m18</th>\n",
       "      <th>m19</th>\n",
       "      <th>m20</th>\n",
       "      <th>m21</th>\n",
       "      <th>m22</th>\n",
       "      <th>m23</th>\n",
       "      <th>m24</th>\n",
       "      <th>m25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572565</td>\n",
       "      <td>-0.014704</td>\n",
       "      <td>-0.352985</td>\n",
       "      <td>-0.012697</td>\n",
       "      <td>-0.138549</td>\n",
       "      <td>0.620313</td>\n",
       "      <td>-0.602656</td>\n",
       "      <td>-0.071517</td>\n",
       "      <td>-0.131941</td>\n",
       "      <td>-0.067118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199931</td>\n",
       "      <td>-0.360027</td>\n",
       "      <td>0.154202</td>\n",
       "      <td>0.369976</td>\n",
       "      <td>0.320812</td>\n",
       "      <td>1.252255</td>\n",
       "      <td>1.154858</td>\n",
       "      <td>0.609724</td>\n",
       "      <td>-0.126952</td>\n",
       "      <td>0.075709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.271232</td>\n",
       "      <td>0.754440</td>\n",
       "      <td>-0.206883</td>\n",
       "      <td>-0.572400</td>\n",
       "      <td>-0.303629</td>\n",
       "      <td>1.783537</td>\n",
       "      <td>0.338053</td>\n",
       "      <td>0.684332</td>\n",
       "      <td>0.780279</td>\n",
       "      <td>0.981463</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112403</td>\n",
       "      <td>-0.317894</td>\n",
       "      <td>0.062038</td>\n",
       "      <td>-0.539969</td>\n",
       "      <td>-0.475836</td>\n",
       "      <td>0.734146</td>\n",
       "      <td>-0.377487</td>\n",
       "      <td>-0.449741</td>\n",
       "      <td>0.386476</td>\n",
       "      <td>0.419884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         m1        m2        m3        m4        m5        m6        m7  \\\n",
       "0  0.572565 -0.014704 -0.352985 -0.012697 -0.138549  0.620313 -0.602656   \n",
       "1 -1.271232  0.754440 -0.206883 -0.572400 -0.303629  1.783537  0.338053   \n",
       "\n",
       "         m8        m9       m10    ...          m16       m17       m18  \\\n",
       "0 -0.071517 -0.131941 -0.067118    ...    -0.199931 -0.360027  0.154202   \n",
       "1  0.684332  0.780279  0.981463    ...     1.112403 -0.317894  0.062038   \n",
       "\n",
       "        m19       m20       m21       m22       m23       m24       m25  \n",
       "0  0.369976  0.320812  1.252255  1.154858  0.609724 -0.126952  0.075709  \n",
       "1 -0.539969 -0.475836  0.734146 -0.377487 -0.449741  0.386476  0.419884  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)- Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)-Backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating backward elimination technique\n",
    "\n",
    "def DoBackwardElimination(the_regressor, X, y, minP2eliminate):\n",
    "    \n",
    "    assert np.shape(X)[0] == np.shape(y)[0], 'Length of X and y do not match'\n",
    "    assert minP2eliminate > 0, 'Minimum P value to eliminate cannot be zero or negative'\n",
    "    \n",
    "    original_list = list(range(0, np.shape(the_regressor.pvalues)[0]))\n",
    "    \n",
    "    max_p = 100        # Initializing with random value of maximum P value\n",
    "    i = 0\n",
    "    r2adjusted = []   # Will store R Square adjusted value for each loop\n",
    "    r2 = []           # Will store R Square value  for each loop\n",
    "    \n",
    "    previous_R2adjusted = the_regressor.rsquared_adj\n",
    "    \n",
    "    while max_p >= minP2eliminate:\n",
    "        \n",
    "        p_values = list(the_regressor.pvalues)\n",
    "        r2adjusted.append(the_regressor.rsquared_adj)\n",
    "        r2.append(the_regressor.rsquared)\n",
    "        \n",
    "        max_p = max(p_values)\n",
    "        max_p_idx = p_values.index(max_p)\n",
    "        \n",
    "        if max_p_idx == 0:\n",
    "            \n",
    "            temp_p = set(p_values)\n",
    "            \n",
    "            # removing the largest element from temp list\n",
    "            temp_p.remove(max(temp_p))\n",
    "            \n",
    "            max_p = max(temp_p)\n",
    "            max_p_idx = p_values.index(max_p)\n",
    "            \n",
    "#             print('Index value 0 found!! Next index value is {}'.format(max_p_idx))\n",
    "            \n",
    "            if max_p < minP2eliminate:\n",
    "                \n",
    "                print('Max P value found less than 0.1 with 0 index ...Loop Ends!!')\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if max_p < minP2eliminate:\n",
    "            \n",
    "            print('Max P value found less than 0.1 without 0 index...Loop Ends!!')\n",
    "            \n",
    "            break\n",
    "        \n",
    "        val_at_idx = original_list[max_p_idx]\n",
    "        \n",
    "        idx_in_org_lst = original_list.index(val_at_idx)\n",
    "        \n",
    "        original_list.remove(val_at_idx)\n",
    "        \n",
    "        print('Popped column index out of original array is {} with P-Value {}'.format(val_at_idx, np.round(np.array(p_values)[max_p_idx], decimals= 4)))\n",
    "        \n",
    "        print('==================================================================================================')\n",
    "        \n",
    "        X_new = X[:, original_list]\n",
    "        \n",
    "        the_regressor = smf.OLS(endog = y, exog = X_new).fit()\n",
    "        \n",
    "        if previous_R2adjusted < the_regressor.rsquared_adj:\n",
    "            classifier_with_maxR2adjusted = the_regressor\n",
    "            final_list_of_index = copy.deepcopy(original_list)\n",
    "            previous_R2adjusted = the_regressor.rsquared_adj\n",
    "            \n",
    "    return classifier_with_maxR2adjusted, r2, r2adjusted, final_list_of_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)-Plot residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resiplot(y_original, y_predicted, delete_outlier = False, max_outlier_val = None):\n",
    "    \n",
    "    residual = y_original - y_predicted\n",
    "    residnew = list(residual.ravel())\n",
    "    \n",
    "    if delete_outlier == True:\n",
    "        assert max_outlier_val != None, 'Please insert \\'max_outlier_val\\''\n",
    "        count = 0\n",
    "        while max(residnew) > abs(max_outlier_val):\n",
    "            count = count + 1\n",
    "            residnew.remove(max(residnew))\n",
    "            \n",
    "        while min(residnew)< -abs(max_outlier_val):\n",
    "            count = count + 1\n",
    "            residnew.remove(min(residnew))\n",
    "        print('Residuals with unreal values are {} i.e. only {}% of total test data.'.format(count, np.round((count/len(residnew)*100), 2)))\n",
    "\n",
    "    plt.scatter(x = range(0, len(residnew)), y = residnew, s = 2, c = 'R')\n",
    "    plt.plot([0,len(residnew)], [0,0], '-k')\n",
    "    if delete_outlier == True:\n",
    "        plt.ylim(-abs(max_outlier_val), abs(max_outlier_val))\n",
    "    elif abs(max(residnew)) > abs(min(residnew)):\n",
    "        plt.ylim(-max(residnew), max(residnew))\n",
    "    else:\n",
    "        plt.ylim(min(residnew), abs(min(residnew)))\n",
    "        \n",
    "    plt.title('Mean residual is {}'.format(np.round(np.mean(residnew),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Splitting data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all columns except last one that is 'm25'.\n",
    "\n",
    "X = df.iloc[:,:-1].values          \n",
    "y = df['m25'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57256488, -0.01470396, -0.35298469, ...,  1.1548579 ,\n",
       "         0.60972403, -0.12695157],\n",
       "       [-1.27123156,  0.75443995, -0.20688296, ..., -0.37748682,\n",
       "        -0.44974088,  0.38647552],\n",
       "       [-0.77836448, -0.45371563, -2.10020124, ...,  0.18666614,\n",
       "         0.21163226, -0.56662082],\n",
       "       ...,\n",
       "       [ 0.73740991, -0.5590069 ,  0.14355845, ..., -0.98605973,\n",
       "         0.20485423, -0.16246918],\n",
       "       [ 0.1151475 , -1.04815064,  0.65888561, ...,  1.15475919,\n",
       "         1.25093225,  1.49547161],\n",
       "       [ 0.3145309 ,  0.77643942,  0.96305974, ..., -0.15680151,\n",
       "         1.68539657,  0.16798312]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07570943,  0.41988445, -1.00067051, ..., -0.55195226,\n",
       "        0.32491959, -0.52513385])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Applying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)-Using econometrics concepts\n",
    "\n",
    "Apply statsmodels for regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   55.03</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>7.98e-262</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:26:15</td>     <th>  Log-Likelihood:    </th> <td>-1.0525e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 80000</td>      <th>  AIC:               </th>  <td>2.106e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 79975</td>      <th>  BIC:               </th>  <td>2.108e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0048</td> <td>    0.003</td> <td>   -1.500</td> <td> 0.134</td> <td>   -0.011</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0003</td> <td>    0.004</td> <td>   -0.080</td> <td> 0.937</td> <td>   -0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0011</td> <td>    0.004</td> <td>   -0.296</td> <td> 0.767</td> <td>   -0.008</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0028</td> <td>    0.004</td> <td>   -0.776</td> <td> 0.438</td> <td>   -0.010</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0038</td> <td>    0.004</td> <td>   -1.075</td> <td> 0.283</td> <td>   -0.011</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 8.454e-05</td> <td>    0.004</td> <td>    0.024</td> <td> 0.981</td> <td>   -0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0037</td> <td>    0.004</td> <td>    1.044</td> <td> 0.296</td> <td>   -0.003</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0002</td> <td>    0.004</td> <td>   -0.051</td> <td> 0.959</td> <td>   -0.007</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0016</td> <td>    0.004</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.009</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0019</td> <td>    0.004</td> <td>   -0.541</td> <td> 0.589</td> <td>   -0.009</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0028</td> <td>    0.004</td> <td>    0.779</td> <td> 0.436</td> <td>   -0.004</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0010</td> <td>    0.004</td> <td>   -0.278</td> <td> 0.781</td> <td>   -0.008</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0010</td> <td>    0.004</td> <td>    0.281</td> <td> 0.779</td> <td>   -0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0272</td> <td>    0.004</td> <td>    7.674</td> <td> 0.000</td> <td>    0.020</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0235</td> <td>    0.004</td> <td>    6.638</td> <td> 0.000</td> <td>    0.017</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.0260</td> <td>    0.004</td> <td>    7.290</td> <td> 0.000</td> <td>    0.019</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0386</td> <td>    0.004</td> <td>   10.841</td> <td> 0.000</td> <td>    0.032</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0328</td> <td>    0.004</td> <td>    9.243</td> <td> 0.000</td> <td>    0.026</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0341</td> <td>    0.004</td> <td>    9.580</td> <td> 0.000</td> <td>    0.027</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0282</td> <td>    0.004</td> <td>    7.914</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    0.0298</td> <td>    0.004</td> <td>    8.399</td> <td> 0.000</td> <td>    0.023</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.0284</td> <td>    0.004</td> <td>    8.030</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0277</td> <td>    0.004</td> <td>    7.835</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.0325</td> <td>    0.004</td> <td>    9.168</td> <td> 0.000</td> <td>    0.026</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.0340</td> <td>    0.004</td> <td>    9.571</td> <td> 0.000</td> <td>    0.027</td> <td>    0.041</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.757</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.153</td> <th>  Jarque-Bera (JB):  </th> <td>   3.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.009</td> <th>  Prob(JB):          </th> <td>   0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.028</td> <th>  Cond. No.          </th> <td>    1.44</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     55.03\n",
       "Date:                Wed, 07 Aug 2019   Prob (F-statistic):          7.98e-262\n",
       "Time:                        17:26:15   Log-Likelihood:            -1.0525e+05\n",
       "No. Observations:               80000   AIC:                         2.106e+05\n",
       "Df Residuals:                   79975   BIC:                         2.108e+05\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0048      0.003     -1.500      0.134      -0.011       0.001\n",
       "x1            -0.0003      0.004     -0.080      0.937      -0.007       0.007\n",
       "x2            -0.0011      0.004     -0.296      0.767      -0.008       0.006\n",
       "x3            -0.0028      0.004     -0.776      0.438      -0.010       0.004\n",
       "x4            -0.0038      0.004     -1.075      0.283      -0.011       0.003\n",
       "x5          8.454e-05      0.004      0.024      0.981      -0.007       0.007\n",
       "x6             0.0037      0.004      1.044      0.296      -0.003       0.011\n",
       "x7            -0.0002      0.004     -0.051      0.959      -0.007       0.007\n",
       "x8            -0.0016      0.004     -0.447      0.655      -0.009       0.005\n",
       "x9            -0.0019      0.004     -0.541      0.589      -0.009       0.005\n",
       "x10            0.0028      0.004      0.779      0.436      -0.004       0.010\n",
       "x11           -0.0010      0.004     -0.278      0.781      -0.008       0.006\n",
       "x12            0.0010      0.004      0.281      0.779      -0.006       0.008\n",
       "x13            0.0272      0.004      7.674      0.000       0.020       0.034\n",
       "x14            0.0235      0.004      6.638      0.000       0.017       0.030\n",
       "x15            0.0260      0.004      7.290      0.000       0.019       0.033\n",
       "x16            0.0386      0.004     10.841      0.000       0.032       0.046\n",
       "x17            0.0328      0.004      9.243      0.000       0.026       0.040\n",
       "x18            0.0341      0.004      9.580      0.000       0.027       0.041\n",
       "x19            0.0282      0.004      7.914      0.000       0.021       0.035\n",
       "x20            0.0298      0.004      8.399      0.000       0.023       0.037\n",
       "x21            0.0284      0.004      8.030      0.000       0.021       0.035\n",
       "x22            0.0277      0.004      7.835      0.000       0.021       0.035\n",
       "x23            0.0325      0.004      9.168      0.000       0.026       0.039\n",
       "x24            0.0340      0.004      9.571      0.000       0.027       0.041\n",
       "==============================================================================\n",
       "Omnibus:                        3.757   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.153   Jarque-Bera (JB):                3.787\n",
       "Skew:                          -0.009   Prob(JB):                        0.151\n",
       "Kurtosis:                       3.028   Cond. No.                         1.44\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "X = np.append(arr=np.ones((80000, 1)).astype(int), values=X, axis=1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will take into account only those variables whose p-value is less than 0.05 i.e 5%. All those variables from 13-24 are significant. Rest do not satisfy our p-values so, we will consider them insignificant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)-backward elimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.016</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   109.7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>2.67e-272</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:26:15</td>     <th>  Log-Likelihood:    </th> <td>-1.0526e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 80000</td>      <th>  AIC:               </th>  <td>2.105e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 79988</td>      <th>  BIC:               </th>  <td>2.106e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>    0.0270</td> <td>    0.004</td> <td>    7.650</td> <td> 0.000</td> <td>    0.020</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>    0.0234</td> <td>    0.004</td> <td>    6.623</td> <td> 0.000</td> <td>    0.016</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.0259</td> <td>    0.004</td> <td>    7.283</td> <td> 0.000</td> <td>    0.019</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>    0.0386</td> <td>    0.004</td> <td>   10.857</td> <td> 0.000</td> <td>    0.032</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>    0.0328</td> <td>    0.004</td> <td>    9.289</td> <td> 0.000</td> <td>    0.026</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>    0.0341</td> <td>    0.004</td> <td>    9.606</td> <td> 0.000</td> <td>    0.027</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.0281</td> <td>    0.004</td> <td>    7.919</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>    0.0297</td> <td>    0.004</td> <td>    8.402</td> <td> 0.000</td> <td>    0.023</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.0284</td> <td>    0.004</td> <td>    8.045</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.0278</td> <td>    0.004</td> <td>    7.879</td> <td> 0.000</td> <td>    0.021</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.0325</td> <td>    0.004</td> <td>    9.178</td> <td> 0.000</td> <td>    0.026</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>    0.0340</td> <td>    0.004</td> <td>    9.587</td> <td> 0.000</td> <td>    0.027</td> <td>    0.041</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.720</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.156</td> <th>  Jarque-Bera (JB):  </th> <td>   3.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.009</td> <th>  Prob(JB):          </th> <td>   0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.028</td> <th>  Cond. No.          </th> <td>    1.25</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.016\n",
       "Method:                 Least Squares   F-statistic:                     109.7\n",
       "Date:                Wed, 07 Aug 2019   Prob (F-statistic):          2.67e-272\n",
       "Time:                        17:26:15   Log-Likelihood:            -1.0526e+05\n",
       "No. Observations:               80000   AIC:                         2.105e+05\n",
       "Df Residuals:                   79988   BIC:                         2.106e+05\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0270      0.004      7.650      0.000       0.020       0.034\n",
       "x2             0.0234      0.004      6.623      0.000       0.016       0.030\n",
       "x3             0.0259      0.004      7.283      0.000       0.019       0.033\n",
       "x4             0.0386      0.004     10.857      0.000       0.032       0.046\n",
       "x5             0.0328      0.004      9.289      0.000       0.026       0.040\n",
       "x6             0.0341      0.004      9.606      0.000       0.027       0.041\n",
       "x7             0.0281      0.004      7.919      0.000       0.021       0.035\n",
       "x8             0.0297      0.004      8.402      0.000       0.023       0.037\n",
       "x9             0.0284      0.004      8.045      0.000       0.021       0.035\n",
       "x10            0.0278      0.004      7.879      0.000       0.021       0.035\n",
       "x11            0.0325      0.004      9.178      0.000       0.026       0.039\n",
       "x12            0.0340      0.004      9.587      0.000       0.027       0.041\n",
       "==============================================================================\n",
       "Omnibus:                        3.720   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.156   Jarque-Bera (JB):                3.750\n",
       "Skew:                          -0.009   Prob(JB):                        0.153\n",
       "Kurtosis:                       3.028   Cond. No.                         1.25\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [13, 14, 15, 16, 17,18,19,20,21,22,23,24]]\n",
    "#regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a very low R2 value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)- Re-applying model after backward elimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LinearRegression()\n",
    "clf_lr.fit(X_opt , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13891801,  0.07357355,  0.05625965, -0.13652366, -0.11772136])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)**0.5\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE    : 0.82 \n",
      "MAE    : 0.72 \n",
      "RMSE   : 0.90 \n",
      "R2     : 0.02 \n"
     ]
    }
   ],
   "source": [
    "print('MSE    : %0.2f ' % mse)\n",
    "print('MAE    : %0.2f ' % mae)\n",
    "print('RMSE   : %0.2f ' % rmse)\n",
    "print('R2     : %0.2f ' % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We got some improvment there in R2 as we removed non-significant features. Earlier, it was 0.016 and now we have 0.02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
