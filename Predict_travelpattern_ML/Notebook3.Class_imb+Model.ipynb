{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qp6Jzx49W_ta"
   },
   "source": [
    "# Prediction of customers' travel pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "- Loading data.\n",
    "- Model Building.\n",
    "- Dealing with imbalnced class problem.\n",
    "- Choosing most relevant features.\n",
    "- Using train-test split and also K-fold approaches for model evaluation, perfomance and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)-Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V11g1goXDyF"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For modeling building and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)-Loading and processing data\n",
    "\n",
    "Loading from notebook2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45805, 515)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('selected_feature.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>num_family</th>\n",
       "      <th>len_jour</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>origin_ADB</th>\n",
       "      <th>origin_ADL</th>\n",
       "      <th>origin_AER</th>\n",
       "      <th>origin_AGP</th>\n",
       "      <th>origin_AKL</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_YEG</th>\n",
       "      <th>dest_YMQ</th>\n",
       "      <th>dest_YOW</th>\n",
       "      <th>dest_YTO</th>\n",
       "      <th>dest_YUL</th>\n",
       "      <th>dest_YVR</th>\n",
       "      <th>dest_YWG</th>\n",
       "      <th>dest_YYC</th>\n",
       "      <th>dest_YYZ</th>\n",
       "      <th>dest_ZRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5834.154716</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6525.926149</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>469.781624</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1498.817537</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2921.339028</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_type     distance  num_family  len_jour  ts_hour  origin_ADB  \\\n",
       "0           0  5834.154716           7       6.0       11           0   \n",
       "1           1  6525.926149           4      21.0       20           0   \n",
       "2           1   469.781624           2       3.0       23           0   \n",
       "3           1  1498.817537           1       3.0       15           0   \n",
       "4           1  2921.339028           4       6.0       22           0   \n",
       "\n",
       "   origin_ADL  origin_AER  origin_AGP  origin_AKL  ...  dest_YEG  dest_YMQ  \\\n",
       "0           0           0           0           0  ...         0         0   \n",
       "1           0           0           0           0  ...         0         0   \n",
       "2           0           0           0           0  ...         0         0   \n",
       "3           0           0           0           0  ...         0         0   \n",
       "4           0           0           0           0  ...         0         0   \n",
       "\n",
       "   dest_YOW  dest_YTO  dest_YUL  dest_YVR  dest_YWG  dest_YYC  dest_YYZ  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   dest_ZRH  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>num_family</th>\n",
       "      <th>len_jour</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>origin_ADB</th>\n",
       "      <th>origin_ADL</th>\n",
       "      <th>origin_AER</th>\n",
       "      <th>origin_AGP</th>\n",
       "      <th>origin_AKL</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_YEG</th>\n",
       "      <th>dest_YMQ</th>\n",
       "      <th>dest_YOW</th>\n",
       "      <th>dest_YTO</th>\n",
       "      <th>dest_YUL</th>\n",
       "      <th>dest_YVR</th>\n",
       "      <th>dest_YWG</th>\n",
       "      <th>dest_YYC</th>\n",
       "      <th>dest_YYZ</th>\n",
       "      <th>dest_ZRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5834.154716</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6525.926149</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>469.781624</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1498.817537</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2921.339028</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_type     distance  num_family  len_jour  ts_hour  origin_ADB  \\\n",
       "0           0  5834.154716           7       6.0       11           0   \n",
       "1           1  6525.926149           4      21.0       20           0   \n",
       "2           1   469.781624           2       3.0       23           0   \n",
       "3           1  1498.817537           1       3.0       15           0   \n",
       "4           1  2921.339028           4       6.0       22           0   \n",
       "\n",
       "   origin_ADL  origin_AER  origin_AGP  origin_AKL  ...  dest_YEG  dest_YMQ  \\\n",
       "0           0           0           0           0  ...         0         0   \n",
       "1           0           0           0           0  ...         0         0   \n",
       "2           0           0           0           0  ...         0         0   \n",
       "3           0           0           0           0  ...         0         0   \n",
       "4           0           0           0           0  ...         0         0   \n",
       "\n",
       "   dest_YOW  dest_YTO  dest_YUL  dest_YVR  dest_YWG  dest_YYC  dest_YYZ  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   dest_ZRH  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spliting data into dependent and independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df_model[\"event_type\"]\n",
    "features=df_model.drop(['event_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45805,)\n",
      "(45805, 514)\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>num_family</th>\n",
       "      <th>len_jour</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>origin_ADB</th>\n",
       "      <th>origin_ADL</th>\n",
       "      <th>origin_AER</th>\n",
       "      <th>origin_AGP</th>\n",
       "      <th>origin_AKL</th>\n",
       "      <th>origin_ALA</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_YEG</th>\n",
       "      <th>dest_YMQ</th>\n",
       "      <th>dest_YOW</th>\n",
       "      <th>dest_YTO</th>\n",
       "      <th>dest_YUL</th>\n",
       "      <th>dest_YVR</th>\n",
       "      <th>dest_YWG</th>\n",
       "      <th>dest_YYC</th>\n",
       "      <th>dest_YYZ</th>\n",
       "      <th>dest_ZRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5834.154716</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6525.926149</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      distance  num_family  len_jour  ts_hour  origin_ADB  origin_ADL  \\\n",
       "0  5834.154716           7       6.0       11           0           0   \n",
       "1  6525.926149           4      21.0       20           0           0   \n",
       "\n",
       "   origin_AER  origin_AGP  origin_AKL  origin_ALA  ...  dest_YEG  dest_YMQ  \\\n",
       "0           0           0           0           0  ...         0         0   \n",
       "1           0           0           0           0  ...         0         0   \n",
       "\n",
       "   dest_YOW  dest_YTO  dest_YUL  dest_YVR  dest_YWG  dest_YYC  dest_YYZ  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   dest_ZRH  \n",
       "0         0  \n",
       "1         0  \n",
       "\n",
       "[2 rows x 514 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize data\n",
    "\n",
    "to deal with outlier issue seen in last notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)-Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32063, 514)\n",
      "(13742, 514)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32063,)\n",
      "(13742,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35177902,  1.0152115 , -0.61244991, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844],\n",
       "       [-0.50221793,  0.15374868, -0.15216897, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844],\n",
       "       [-0.69762774, -0.70771413, -0.21792339, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844],\n",
       "       ...,\n",
       "       [ 1.98983893,  1.0152115 ,  3.53007847, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844],\n",
       "       [-0.50391064, -0.70771413,  0.76839289, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844],\n",
       "       [-0.73094009,  0.15374868, -0.34943223, ..., -0.03371257,\n",
       "        -0.03135908, -0.08173844]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Classifeir\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_LR[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9598311745015282\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4998931390669304\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     13217\n",
      "           1       0.03      0.00      0.00       525\n",
      "\n",
      "    accuracy                           0.96     13742\n",
      "   macro avg       0.50      0.50      0.49     13742\n",
      "weighted avg       0.93      0.96      0.94     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that there is problem of imbalanced class. For booking results , we get very poor precision score of only 0.03 and for search events, we have 0.96. We need to solve this problem as we want a model that performs more precisely on booking instances than search results.\n",
    "\n",
    "As for accuracy, it is very good. But, this does not make much value for our case. Also it makes case that accuracy is not always a good evaluation matric for checking model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_test, predictions_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13189,    28],\n",
       "       [  524,     1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does predict only 1 correct booking instance whereas 524 booking instances are incorrectly predicted as search instances. This is really bad for our case. We need a model that could predict booking instance correctly. even though we have an accuracy of 95%, we fail to get our required results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precicion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96178808, 0.96551724],\n",
       "       [0.03821192, 0.03448276]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P =(C/C.sum(axis=0))\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99788152, 0.00211848],\n",
       "       [0.99809524, 0.00190476]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A =(((C.T)/(C.sum(axis=1))).T)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Solution to imbalanced Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution1: Under-sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = df_model[df_model['event_type']==1]\n",
    "\n",
    "search = df_model[df_model['event_type']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df_model[\"event_type\"]\n",
    "features=df_model.drop(['event_type'], axis=1)\n",
    "X = StandardScaler().fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "# Implementing Undersampling for Handling Imbalanced \n",
    "nm = NearMiss()\n",
    "X_under,y_under=nm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2566, 514) (2566,)\n"
     ]
    }
   ],
   "source": [
    "print(X_under.shape,y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    30780\n",
      "1     1283\n",
      "Name: event_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking classes\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1283\n",
      "0    1283\n",
      "Name: event_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_under.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13217\n",
      "1      525\n",
      "Name: event_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13742,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Classifeir\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_under, y_under)\n",
    "predictions_LR_under = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22165623635569787\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions_LR_under,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.95      0.33      2793\n",
      "           1       0.74      0.04      0.07     10949\n",
      "\n",
      "    accuracy                           0.22     13742\n",
      "   macro avg       0.47      0.49      0.20     13742\n",
      "weighted avg       0.63      0.22      0.12     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_LR_under,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49341759863955387\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(predictions_LR_under,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03552835875422413\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(predictions_LR_under,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06780547324385568\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(predictions_LR_under,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could better results that our 1st model. Let's see what are other solutions in bag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: Over-Sampling\n",
    "\n",
    "adding artificial values to our training data. Mind you, we wont over sample test data. It will be a mistake as we only make our training data to learn and test that learning on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Oversampling for Handling Imbalanced \n",
    "smk = SMOTETomek(random_state=42)\n",
    "X_over,y_over=smk.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60868, 514), (60868,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape,y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13742, 514), (13742,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_over, y_over)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5406782127783437\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5092671954659488\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.97      0.69      7339\n",
      "           1       0.59      0.05      0.09      6403\n",
      "\n",
      "    accuracy                           0.54     13742\n",
      "   macro avg       0.56      0.51      0.39     13742\n",
      "weighted avg       0.56      0.54      0.41     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that keeping a balanced class will give us a balanced precision result.It is still not very impressive on recall or f1 though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3: Using class_weight option as \"balanced\" \n",
    "\n",
    "\n",
    "using model for class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5813564255566875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5119320419309547\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73      7908\n",
      "           1       0.58      0.05      0.10      5834\n",
      "\n",
      "    accuracy                           0.58     13742\n",
      "   macro avg       0.58      0.51      0.41     13742\n",
      "weighted avg       0.58      0.58      0.46     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three solutions. Oversample whether SMOTE or model option class balance give almost same results. With model option class balance, it does not seem like a big issue. But, I am going to choose under-sampling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we choose under sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three reasons\n",
    "\n",
    "- 1)- Our task is not to create a model for predicting accurate results for search and booking event classes. Our task is to find conversion-likelihood. Idea is to create a model that predicts very good results for booking events. If that model is not good in prediction of search event types then we won't mind. \n",
    "\n",
    "- 2)- As per my first interaction, our organization has got enough data. So, if we lose some samples then it is not big deal. I will consider it as first prototype round.In intital stage, we get less data and later we scale up project. If we get more data then this code will perform well for scaled data. Main concern is to deal with imbalanced classes and still to get good results for booking event type instances. That's why we can optimal model with our Solution 1. I have given other solutions as to know that I have knowledge of solutions.\n",
    "\n",
    "- 3-If we apply more intense ML or DL models then over-sampling models will take alot of computing. If that is valuebale then sure , I would not mind high computation cost. But, in this assignment we can get pretty good results with under-sampling as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)- Choosing features\n",
    "\n",
    "3 features vs six featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_model[\"event_type\"]\n",
    "features=df_model[[\"distance\",\"num_family\",\"len_jour\",\"ts_hour\"]]\n",
    "X = StandardScaler().fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "nm = NearMiss()\n",
    "X_under,y_under=nm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)- Using Statsmodel for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.167024\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.006</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>event_type</td>          <td>AIC:</td>        <td>10720.5885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-28 23:26</td>       <td>BIC:</td>        <td>10762.4658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>32063</td>       <td>Log-Likelihood:</td>    <td>-5355.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>4</td>            <td>LL-Null:</td>        <td>-5386.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>32058</td>        <td>LLR p-value:</td>    <td>1.0759e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>8.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>     <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-3.2045</td>  <td>0.0293</td>  <td>-109.2954</td> <td>0.0000</td> <td>-3.2620</td> <td>-3.1471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-0.2063</td>  <td>0.0360</td>   <td>-5.7304</td>  <td>0.0000</td> <td>-0.2769</td> <td>-0.1357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>0.0515</td>   <td>0.0270</td>   <td>1.9099</td>   <td>0.0561</td> <td>-0.0013</td> <td>0.1044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-0.0825</td>  <td>0.0398</td>   <td>-2.0720</td>  <td>0.0383</td> <td>-0.1605</td> <td>-0.0045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>0.0052</td>   <td>0.0286</td>   <td>0.1824</td>   <td>0.8553</td> <td>-0.0508</td> <td>0.0613</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.006     \n",
       "Dependent Variable: event_type       AIC:              10720.5885\n",
       "Date:               2020-03-28 23:26 BIC:              10762.4658\n",
       "No. Observations:   32063            Log-Likelihood:   -5355.3   \n",
       "Df Model:           4                LL-Null:          -5386.3   \n",
       "Df Residuals:       32058            LLR p-value:      1.0759e-12\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     8.0000                                       \n",
       "-------------------------------------------------------------------\n",
       "         Coef.    Std.Err.       z       P>|z|     [0.025    0.975]\n",
       "-------------------------------------------------------------------\n",
       "const   -3.2045     0.0293   -109.2954   0.0000   -3.2620   -3.1471\n",
       "x1      -0.2063     0.0360     -5.7304   0.0000   -0.2769   -0.1357\n",
       "x2       0.0515     0.0270      1.9099   0.0561   -0.0013    0.1044\n",
       "x3      -0.0825     0.0398     -2.0720   0.0383   -0.1605   -0.0045\n",
       "x4       0.0052     0.0286      0.1824   0.8553   -0.0508    0.0613\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logistic= sm.Logit(y_train,sm.add_constant(X_train)).fit()\n",
    "logistic.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ts_hour i. x4 is not significant as compare to p-value. So we can remove it from equation.\n",
    "- num_family is marginal significant so, we shall keep it for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)- Using sklearn for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_under, y_under)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24465143356134478\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.94      0.37      3195\n",
      "           1       0.66      0.03      0.06     10547\n",
      "\n",
      "    accuracy                           0.24     13742\n",
      "   macro avg       0.44      0.49      0.22     13742\n",
      "weighted avg       0.56      0.24      0.13     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is lower than our six feature model. So, it shows that those categorical variables(origin and destination) improved performance. We cannot leave them aside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3)- Applying with removal of insignificant variable\n",
    "\n",
    "\n",
    "using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_model[\"event_type\"]\n",
    "features=df_model[[\"distance\",\"num_family\",\"len_jour\"]]\n",
    "X = StandardScaler().fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "nm = NearMiss()\n",
    "X_under,y_under=nm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.167025\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.006</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>event_type</td>          <td>AIC:</td>        <td>10718.6218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-28 23:27</td>       <td>BIC:</td>        <td>10752.1236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>32063</td>       <td>Log-Likelihood:</td>    <td>-5355.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>        <td>-5386.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>32059</td>        <td>LLR p-value:</td>    <td>2.1806e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>8.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>     <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-3.2045</td>  <td>0.0293</td>  <td>-109.2960</td> <td>0.0000</td> <td>-3.2620</td> <td>-3.1470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-0.2063</td>  <td>0.0360</td>   <td>-5.7297</td>  <td>0.0000</td> <td>-0.2768</td> <td>-0.1357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>0.0515</td>   <td>0.0270</td>   <td>1.9097</td>   <td>0.0562</td> <td>-0.0014</td> <td>0.1044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-0.0826</td>  <td>0.0398</td>   <td>-2.0751</td>  <td>0.0380</td> <td>-0.1606</td> <td>-0.0046</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.006     \n",
       "Dependent Variable: event_type       AIC:              10718.6218\n",
       "Date:               2020-03-28 23:27 BIC:              10752.1236\n",
       "No. Observations:   32063            Log-Likelihood:   -5355.3   \n",
       "Df Model:           3                LL-Null:          -5386.3   \n",
       "Df Residuals:       32059            LLR p-value:      2.1806e-13\n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     8.0000                                       \n",
       "-------------------------------------------------------------------\n",
       "         Coef.    Std.Err.       z       P>|z|     [0.025    0.975]\n",
       "-------------------------------------------------------------------\n",
       "const   -3.2045     0.0293   -109.2960   0.0000   -3.2620   -3.1470\n",
       "x1      -0.2063     0.0360     -5.7297   0.0000   -0.2768   -0.1357\n",
       "x2       0.0515     0.0270      1.9097   0.0562   -0.0014    0.1044\n",
       "x3      -0.0826     0.0398     -2.0751   0.0380   -0.1606   -0.0046\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic= sm.Logit(y_train,sm.add_constant(X_train)).fit()\n",
    "logistic.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4)- Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_under, y_under)\n",
    "predictions_LR = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24043079609954882\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.94      0.36      3141\n",
      "           1       0.66      0.03      0.06     10601\n",
      "\n",
      "    accuracy                           0.24     13742\n",
      "   macro avg       0.44      0.49      0.21     13742\n",
      "weighted avg       0.56      0.24      0.13     13742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_LR,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not same but, somewhat similar. Removal for one variable has not made much impact. \n",
    "\n",
    "still we will keep this three feature approached dropped and continue with five feature model. I am taking this liberty NOT to confine my model to three features as was directed in assignment.This is the only time I am deviating from assignments' instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)- Update Dataset\n",
    "\n",
    "with five features in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_type</th>\n",
       "      <th>distance</th>\n",
       "      <th>num_family</th>\n",
       "      <th>len_jour</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>origin_ADB</th>\n",
       "      <th>origin_ADL</th>\n",
       "      <th>origin_AER</th>\n",
       "      <th>origin_AGP</th>\n",
       "      <th>origin_AKL</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_YEG</th>\n",
       "      <th>dest_YMQ</th>\n",
       "      <th>dest_YOW</th>\n",
       "      <th>dest_YTO</th>\n",
       "      <th>dest_YUL</th>\n",
       "      <th>dest_YVR</th>\n",
       "      <th>dest_YWG</th>\n",
       "      <th>dest_YYC</th>\n",
       "      <th>dest_YYZ</th>\n",
       "      <th>dest_ZRH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5834.154716</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6525.926149</td>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>469.781624</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1498.817537</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2921.339028</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_type     distance  num_family  len_jour  ts_hour  origin_ADB  \\\n",
       "0           0  5834.154716           7       6.0       11           0   \n",
       "1           1  6525.926149           4      21.0       20           0   \n",
       "2           1   469.781624           2       3.0       23           0   \n",
       "3           1  1498.817537           1       3.0       15           0   \n",
       "4           1  2921.339028           4       6.0       22           0   \n",
       "\n",
       "   origin_ADL  origin_AER  origin_AGP  origin_AKL  ...  dest_YEG  dest_YMQ  \\\n",
       "0           0           0           0           0  ...         0         0   \n",
       "1           0           0           0           0  ...         0         0   \n",
       "2           0           0           0           0  ...         0         0   \n",
       "3           0           0           0           0  ...         0         0   \n",
       "4           0           0           0           0  ...         0         0   \n",
       "\n",
       "   dest_YOW  dest_YTO  dest_YUL  dest_YVR  dest_YWG  dest_YYC  dest_YYZ  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   dest_ZRH  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ts_hour'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('updated_feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)- K-Fold \n",
    "\n",
    "Using balanced class data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "df_model = pd.read_csv('updated_feature.csv')\n",
    "y=df_model[\"event_type\"]\n",
    "features=df_model.drop(['event_type'], axis=1)\n",
    "X = StandardScaler().fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold 1:\n",
      "Accuracy: 0.1945202488811265\n",
      "f-score: 0.31326198231735686\n",
      "roc-auc: 0.5125469273921022\n",
      "recall: 0.18611080393674664\n",
      "precision: 0.9888366627497063\n",
      "For fold 2:\n",
      "Accuracy: 0.2025979696539679\n",
      "f-score: 0.020908725371934056\n",
      "roc-auc: 0.49891357156652105\n",
      "recall: 0.010597826086956521\n",
      "precision: 0.7722772277227723\n",
      "For fold 3:\n",
      "Accuracy: 0.18404104355419715\n",
      "f-score: 0.0\n",
      "roc-auc: 0.5\n",
      "recall: 0.0\n",
      "precision: 0.0\n",
      "For fold 4:\n",
      "Accuracy: 0.19211876432703853\n",
      "f-score: 0.00027016074564365796\n",
      "roc-auc: 0.5000675493109971\n",
      "recall: 0.00013509862199405565\n",
      "precision: 1.0\n",
      "For fold 5:\n",
      "Accuracy: 0.19069970527235017\n",
      "f-score: 0.0008086253369272238\n",
      "roc-auc: 0.4999157324208789\n",
      "recall: 0.0004045307443365696\n",
      "precision: 0.75\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "    X_train = X[train_index]\n",
    "    y_train = target[train_index]  # Based on our code, you might need a ravel call here, but I would look into how you're generating y\n",
    "    X_test = X[test_index]\n",
    "    y_test = target[test_index] \n",
    "    nm = NearMiss()\n",
    "    X_under,y_under=nm.fit_sample(X_train,y_train)\n",
    "    model = LogisticRegression()  # Choose a model here\n",
    "    model.fit(X_under, y_under )  \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'For fold {fold}:')\n",
    "    print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "    print(f'f-score: {f1_score(y_pred, y_test)}')\n",
    "    print(f'roc-auc: {roc_auc_score(y_pred, y_test)}')\n",
    "    print(f'recall: {recall_score(y_pred, y_test)}')\n",
    "    print(f'precision: {metrics.precision_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation done wrong\n",
    "\n",
    "- Thanks to https://www.youtube.com/watch?v=DQC_YE3I5ig tutorial, I have found what is right and what is wrong way to apply K-fold.\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42) <br>\n",
    "accuracy = [] <br>\n",
    "precision = [] <br>\n",
    "recall = [] <br>\n",
    "f1 = [] <br>\n",
    "auc = [] <br>\n",
    "X, y = SMOTE().fit_sample(X_train, y_train) <br>\n",
    "for train, test in kf.split(X, y): <br>\n",
    "    pipeline = make_pipeline(classifier(random_state=42)) <br>\n",
    "    model = pipeline.fit(X[train], y[train]) <br>\n",
    "    prediction = model.predict(X[test]) <br>\n",
    "    accuracy.append(pipeline.score(X[test], y[test])) <br>\n",
    "    precision.append(precision_score(y[test], prediction)) <br>\n",
    "    recall.append(recall_score(y[test], prediction)) <br>\n",
    "    f1.append(f1_score(y[test], prediction)) <br>\n",
    "\n",
    "print(\"done wrong mean of scores 5-fold:\") <br>\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy))) <br>\n",
    "print(\"precision: {}\".format(np.mean(precision))) <br>\n",
    "print(\"recall: {}\".format(np.mean(recall))) <br>\n",
    "print(\"f1: {}\".format(np.mean(f1))) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally,** we get precison score of 0.75.These results are also very close to our earlier six feature model. But, would Regression Classifier be the only model ? We shall try more ML and DL model in next notebook to see better performance. To summarize ;\n",
    "\n",
    "- Our dataset will be with five features i.e 3 numeric and 2 categorical\n",
    "- We shall use under-sample method as per reason given above\n",
    "- We shall try and compare results of Reg. Classifier with other models\n",
    "- Our matric of evaluation will be precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldvDx7DPUErC"
   },
   "source": [
    "**END OF NOTEBOOK3**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3.Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
